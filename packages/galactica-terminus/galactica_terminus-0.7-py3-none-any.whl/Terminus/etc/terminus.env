# Terminus environment variable
TERMINUS_HOSTNAME="__empty__"
TERMINUS_DOT_DIR="__empty__"
TERMINUS_DATA_DIR="__empty__"
TERMINUS_JOB_DIR="__empty__"

TERMINUS_ROOT="__empty__"
TERMINUS_SERVICE_DIR="__empty__"

TERMINUS_USE_SLURM=0

GALACSTORAGE_SSH_ALIAS="Galactica_storage"
RABBITMQ_USERNAME="__empty__"
RABBITMQ_HOST="__empty__"
RABBITMQ_PORT="__empty__"
RABBITMQ_VIRTUAL_HOST="__empty__"

PATH=/usr/bin

# Celery configuration
# Name of nodes to start : here we have 4 named nodes (1 to N) + 1 monitor node (mandatory)
CELERYD_NODES="job_worker1@anais.terminus job_worker2@anais.terminus job_worker3@anais.terminus job_worker4@anais.terminus monitor@anais.terminus"

# Absolute or relative path to the 'celery' command:
CELERY_BIN="__empty__"

# App instance to use
# comment out this line if you don't use an app
CELERY_APP="Terminus"
# or fully qualified:
#CELERY_APP="Terminus.tasks:app"

# How to call manage.py
CELERYD_MULTI="multi"

# Extra command-line arguments to the worker : listen to the host-specific terminus job queue + monitoring queues.
CELERYD_OPTS="--concurrency=2 -Q hostname.terminus_jobs -c:5 1 -Q:5 hostname.monitor"

# - %n will be replaced with the first part of the nodename.
# - %I will be replaced with the current child process index
#   and is important when using the prefork pool to avoid race conditions.
CELERYD_PID_FILE="__empty__"
CELERYD_LOG_FILE="__empty__"
CELERYD_LOG_LEVEL="INFO"

# PID and LOG directories will be created if missing
CELERY_CREATE_DIRS=1
