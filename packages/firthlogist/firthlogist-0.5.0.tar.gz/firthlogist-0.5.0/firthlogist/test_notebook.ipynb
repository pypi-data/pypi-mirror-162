{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5295e218-84b9-4b31-8fcc-95f6c71d69e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lapack\n",
    "from scipy.special import expit\n",
    "from scipy.stats import chi2\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from firthlogist import FirthLogisticRegression\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b3f255f2-dc4f-4ea1-8e57-4d420e1839e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 17)\n",
      "(20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "# Q = np.random.rand(20000, 17)\n",
    "# def scipy_qr(Q):\n",
    "#     qr, tau, _, _ = lapack.dgeqrf(Q)\n",
    "#     x, _, _ = lapack.dorgqr(qr, tau)\n",
    "#     return x\n",
    "\n",
    "# %timeit np.linalg.qr(Q)\n",
    "# %timeit scipy_qr(Q)\n",
    "\n",
    "preds = np.random.rand(20000)\n",
    "X = np.random.rand(20000, 17)\n",
    "def old(preds, X):\n",
    "    rootW = np.sqrt(preds * (1 - preds))\n",
    "    XW = rootW[:, np.newaxis] * X\n",
    "    qr, tau, _, _ = lapack.dgeqrf(XW)\n",
    "    Q, _, _ = lapack.dorgqr(qr, tau)\n",
    "    hat = np.einsum(\"ij,ij->i\", Q, Q)\n",
    "    return hat\n",
    "\n",
    "def new(preds, X):\n",
    "    rootW = np.sqrt(preds * (1 - preds))\n",
    "#     XW = rootW[:, np.newaxis] * X\n",
    "    XtW = np.multiply(X.T, rootW)\n",
    "    WX = np.multiply(rootW[:, np.newaxis], X)\n",
    "    XtWX = XtW @ X\n",
    "#     print((XtWX @ XtW).shape)\n",
    "    hat_mtx = XW @ np.linalg.solve(XtWX, XtW)\n",
    "    print(XW.shape)\n",
    "    print(hat_mtx.shape)\n",
    "#     fim = XW @ XW.T\n",
    "#     print(np.allclose(XtWX, fim))\n",
    "#     x = np.linalg.solve(XtWX, X.T)\n",
    "#     Q_ = np.einsum('ij,ji->i', X,hat_mtx) \n",
    "#     return Q_\n",
    "new(preds, X)\n",
    "# np.allclose(old(preds, X), new(preds, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97f25a24-f387-447d-ae6f-0d595d0a2956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n",
      "(200, 500000)\n",
      "(200, 500000)\n"
     ]
    }
   ],
   "source": [
    "m = 200\n",
    "n = 500000\n",
    "\n",
    "np.random.seed(123)\n",
    "X = np.random.random((n,m))\n",
    "W_diag = np.random.random(n)            # C -> dense vector\n",
    "\n",
    "\n",
    "lhs = np.multiply(X.T, W_diag).dot(X)   # C (+A)\n",
    "x = np.linalg.solve(lhs, X.T)           # B\n",
    "print(lhs.shape)\n",
    "print(X.T.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1ac9405-5593-430e-85b3-28e5d6246a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04783116, 0.17454019, 0.10998432, ..., 0.03930919, 0.18292077,\n",
       "        0.16507641],\n",
       "       [0.08172705, 0.11543252, 0.09174067, ..., 0.09862448, 0.10468953,\n",
       "        0.01189124],\n",
       "       [0.41615762, 0.27235266, 0.34298398, ..., 0.13732365, 0.16597937,\n",
       "        0.1797666 ],\n",
       "       ...,\n",
       "       [0.30277286, 0.27870828, 0.3397394 , ..., 0.296657  , 0.19384353,\n",
       "        0.14704407],\n",
       "       [0.16671844, 0.13123987, 0.19758824, ..., 0.38240628, 0.19017203,\n",
       "        0.17584479],\n",
       "       [0.27519537, 0.1272537 , 0.21710494, ..., 0.20821412, 0.02053744,\n",
       "        0.213298  ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.multiply(X.T, rootW)\n",
    "# rootW[:, np.newaxis] * X\n",
    "np.multiply(X, rootW[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c97f676-c35b-441d-b0e0-080a76515e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00047494 0.0014886  0.00075984 ... 0.00107517 0.00128043 0.00021424]\n",
      "[0.00316248 0.00255296 0.00134731 ... 0.00211485 0.00230587 0.00208776]\n"
     ]
    }
   ],
   "source": [
    "print(old(preds, X))\n",
    "print(new(preds, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "855a90c2-a044-40cc-a613-159576ad28d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Schedule pythranization: transonic_sum.py\n",
      "Schedule pythranization: transonic_sum.py\n",
      "Schedule pythranization: manual.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythranizing /home/jon/.transonic/pythran/__jit__/__ipython__227c27df279439a4a4c3b3cf22aedc2f/transonic_sum.py\n",
      "lock file /home/jon/.transonic/pythran/__jit__/__ipython__227c27df279439a4a4c3b3cf22aedc2f/transonic_sum_1516e6def7e005fb004ba29d955a06be_cee621790ba67ed1e2c2fa0a6ee38726.lock present: waiting for completion of the compilation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Schedule pythranization: manual.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythranizing /home/jon/.transonic/pythran/__jit__/__ipython__227c27df279439a4a4c3b3cf22aedc2f/manual.py\n",
      "lock file /home/jon/.transonic/pythran/__jit__/__ipython__227c27df279439a4a4c3b3cf22aedc2f/manual_ca769040ca18646de8ac8e0599cbb244_d87f1dabdcce1f5ca567446f575ebe1b.lock present: waiting for completion of the compilation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.46701855, 4.25030818, 5.51264391, ..., 7.23127325, 5.65918928,\n",
       "       7.26287235])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/jon/.transonic/pythran/__jit__/__ipython__227c27df279439a4a4c3b3cf22aedc2f/manual_ca769040ca18646de8ac8e0599cbb244_d87f1dabdcce1f5ca567446f575ebe1b.cpython-310-x86_64-linux-gnu.so created by pythran\n",
      "File /home/jon/.transonic/pythran/__jit__/__ipython__227c27df279439a4a4c3b3cf22aedc2f/transonic_sum_1516e6def7e005fb004ba29d955a06be_cee621790ba67ed1e2c2fa0a6ee38726.cpython-310-x86_64-linux-gnu.so created by pythran\n"
     ]
    }
   ],
   "source": [
    "from transonic import jit, wait_for_all_extensions\n",
    "import numpy as np\n",
    "\n",
    "Q = np.random.rand(20000, 17)\n",
    "\n",
    "def transonic_sum(Q):\n",
    "    hat = np.sum(Q*Q, axis=1)\n",
    "    return hat\n",
    "\n",
    "def manual(Q):\n",
    "    res = np.zeros(Q.shape[0])\n",
    "    for idx, row in enumerate(Q):\n",
    "        rowsum = 0\n",
    "        for col in row:\n",
    "            rowsum += col*col\n",
    "        res[idx] = rowsum\n",
    "    return res\n",
    "    \n",
    "transonic_sum_xsimd = jit(native=True, xsimd=True)(transonic_sum)\n",
    "transonic_sum_noxsimd = jit(native=True, xsimd=False)(transonic_sum)\n",
    "transonic_manual_xsimd = jit(native=True, xsimd=True)(manual)\n",
    "transonic_manual_noxsimd = jit(native=True, xsimd=False)(manual)\n",
    "transonic_sum_xsimd(Q)\n",
    "transonic_sum_noxsimd(Q)\n",
    "transonic_manual_xsimd(Q)\n",
    "transonic_manual_noxsimd(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6193b2ce-86bc-4c8c-9a86-d03e2b79ada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.7 µs ± 55 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "404 µs ± 1.22 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.einsum(\"ij,ij->i\", Q, Q)\n",
    "%timeit np.sum(np.square(Q), axis=1)\n",
    "# %timeit np.sum(Q*Q, axis=1)\n",
    "# %timeit transonic_sum_xsimd(Q)\n",
    "# %timeit transonic_sum_noxsimd(Q)\n",
    "# # %timeit manual(Q)\n",
    "# %timeit transonic_manual_xsimd(Q)\n",
    "# %timeit transonic_manual_noxsimd(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d68966e-b507-464a-b394-f1558142f333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Schedule pythranization: loglike.py\n",
      "/tmp/ipykernel_31521/2569637500.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(y * np.log(preds) + (1 - y) * np.log(1 - preds))\n",
      "/tmp/ipykernel_31521/2569637500.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sum(y * np.log(preds) + (1 - y) * np.log(1 - preds))\n",
      "Schedule pythranization: loglike.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythranizing /home/jon/.transonic/pythran/__jit__/__ipython__ca578a667d4d130c459901814cffe800/loglike.py\n",
      "lock file /home/jon/.transonic/pythran/__jit__/__ipython__ca578a667d4d130c459901814cffe800/loglike_1a2a3d52460439e65005b1b042015697_b3d43e242266d2bba4f32ea82224270e.lock present: waiting for completion of the compilation\n",
      "File /home/jon/.transonic/pythran/__jit__/__ipython__ca578a667d4d130c459901814cffe800/loglike_1a2a3d52460439e65005b1b042015697_b3d43e242266d2bba4f32ea82224270e.cpython-310-x86_64-linux-gnu.so created by pythran\n"
     ]
    }
   ],
   "source": [
    "from transonic import jit, wait_for_all_extensions\n",
    "import numpy as np\n",
    "\n",
    "def loglike(y, preds):\n",
    "    return np.sum(y * np.log(preds) + (1 - y) * np.log(1 - preds))\n",
    "\n",
    "loglike_pythran = jit(native=True, xsimd=False)(loglike)\n",
    "loglike_pythran_xsimd = jit(native=True, xsimd=True)(loglike)\n",
    "loglike_pythran(np.array([0.,1.,1.,0.]), np.array([0.,1.,1.,0.]))\n",
    "loglike_pythran_xsimd(np.array([0.,1.,1.,0.]), np.array([0.,1.,1.,0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7d6abb-4604-4bee-835a-6f7d9d21b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.7 ms ± 114 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.82 ms ± 11.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.82 ms ± 1.66 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.83 ms ± 2.91 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "@njit\n",
    "def numba_jit(y, preds):\n",
    "    return np.sum(y * np.log(preds) + (1 - y) * np.log(1 - preds))\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "numba_jit(a, b)\n",
    "%timeit loglike(a, b)\n",
    "%timeit numba_jit(a, b)\n",
    "%timeit loglike_pythran(a, b)\n",
    "%timeit loglike_pythran_xsimd(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01c2ec63-ea09-46bc-a8b5-05312d9da5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.27 µs ± 118 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "13.3 µs ± 41.4 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(1000)\n",
    "b = np.random.rand(1000)\n",
    "%timeit loglike_jit(a, b)\n",
    "%timeit loglike(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b58c01d-36ac-4f84-bfdc-bac0e1b50dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from copy import deepcopy\n",
    "from importlib.resources import open_text\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import lapack\n",
    "from scipy.special import expit\n",
    "from scipy.stats import chi2\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from tabulate import tabulate\n",
    "# from loglike import loglike\n",
    "\n",
    "\n",
    "class FirthLogisticRegression(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Logistic regression with Firth's bias reduction method.\n",
    "\n",
    "    This is based on the implementation in the `logistf` R package. Please see the\n",
    "    `logistf` reference and Heinze & Schemper (2002) for details about the procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_iter\n",
    "        The maximum number of Newton-Raphson iterations.\n",
    "    max_halfstep\n",
    "        The maximum number of step-halvings in one Newton-Raphson iteration.\n",
    "    max_stepsize\n",
    "        The maximum step size - for each coefficient, the step size is forced to\n",
    "        be less than max_stepsize.\n",
    "    pl_max_iter\n",
    "        The maximum number of Newton-Raphson iterations for finding profile likelihood\n",
    "        confidence intervals.\n",
    "    pl_max_halfstep\n",
    "        The maximum number of step-halvings in one iteration for finding profile\n",
    "        likelihood confidence intervals.\n",
    "    pl_max_stepsize\n",
    "        The maximum step size while finding PL confidence intervals.\n",
    "    tol\n",
    "        Convergence tolerance for stopping.\n",
    "    fit_intercept\n",
    "        Specifies if intercept should be added.\n",
    "    skip_lrt\n",
    "        If True, p-values will not be calculated. Calculating the p-values can be\n",
    "        time-consuming since the fitting procedure is repeated for each coefficient.\n",
    "    skip_ci\n",
    "        If True, confidence intervals will not be calculated. Calculating the confidence\n",
    "        intervals via profile likelihoood is time-consuming.\n",
    "    alpha\n",
    "        Significance level (confidence interval = 1-alpha). 0.05 as default for 95% CI.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    bse_\n",
    "        Standard errors of the coefficients.\n",
    "    classes_\n",
    "        A list of the class labels.\n",
    "    ci_\n",
    "        The fitted profile likelihood confidence intervals.\n",
    "    coef_\n",
    "        The coefficients of the features.\n",
    "    intercept_\n",
    "        Fitted intercept. If `fit_intercept = False`, the intercept is set to zero.\n",
    "    loglik_\n",
    "        Fitted penalized log-likelihood.\n",
    "    n_iter_\n",
    "        Number of Newton-Raphson iterations performed.\n",
    "    pvals_\n",
    "        p-values calculated by penalized likelihood ratio tests.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Firth D (1993). Bias reduction of maximum likelihood estimates.\n",
    "    Biometrika 80, 27–38.\n",
    "\n",
    "    Heinze G, Schemper M (2002). A solution to the problem of separation in logistic\n",
    "    regression. Statistics in Medicine 21: 2409-2419.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iter=25,\n",
    "        max_halfstep=0,\n",
    "        max_stepsize=5,\n",
    "        pl_max_iter=100,\n",
    "        pl_max_halfstep=0,\n",
    "        pl_max_stepsize=5,\n",
    "        tol=0.0001,\n",
    "        fit_intercept=True,\n",
    "        skip_lrt=False,\n",
    "        skip_ci=False,\n",
    "        alpha=0.05,\n",
    "        jit = False\n",
    "    ):\n",
    "        self.max_iter = max_iter\n",
    "        self.max_stepsize = max_stepsize\n",
    "        self.max_halfstep = max_halfstep\n",
    "        self.pl_max_iter = pl_max_iter\n",
    "        self.pl_max_halfstep = pl_max_halfstep\n",
    "        self.pl_max_stepsize = pl_max_stepsize\n",
    "        self.tol = tol\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.skip_lrt = skip_lrt\n",
    "        self.skip_ci = skip_ci\n",
    "        self.alpha = alpha\n",
    "        self.jit = jit\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {\"binary_only\": True}\n",
    "\n",
    "    def _validate_input(self, X, y):\n",
    "        if self.max_iter < 0:\n",
    "            raise ValueError(\n",
    "                f\"Maximum number of iterations must be positive; \"\n",
    "                f\"got max_iter={self.max_iter}\"\n",
    "            )\n",
    "        if self.max_halfstep < 0:\n",
    "            raise ValueError(\n",
    "                f\"Maximum number of step-halvings must >= 0; \"\n",
    "                f\"got max_halfstep={self.max_iter}\"\n",
    "            )\n",
    "        if self.tol < 0:\n",
    "            raise ValueError(\n",
    "                f\"Tolerance for stopping criteria must be positive; got tol={self.tol}\"\n",
    "            )\n",
    "        X, y = self._validate_data(X, y, dtype=np.float64, ensure_min_samples=2)\n",
    "        check_classification_targets(y)\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        if len(self.classes_) != 2:\n",
    "            raise ValueError(f\"Got {len(self.classes_)} - only 2 classes supported.\")\n",
    "        y = LabelEncoder().fit_transform(y).astype(X.dtype, copy=False)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = self._validate_input(X, y)\n",
    "        if self.fit_intercept:\n",
    "            X = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "\n",
    "        self.coef_, self.loglik_, self.n_iter_ = _firth_newton_raphson(\n",
    "            X, y, self.max_iter, self.max_stepsize, self.max_halfstep, self.tol, jit=self.jit\n",
    "        )\n",
    "\n",
    "        self.bse_ = _bse(X, self.coef_)\n",
    "\n",
    "        if not self.skip_ci:\n",
    "            self.ci_ = np.column_stack(\n",
    "                [\n",
    "                    _profile_likelihood_ci(\n",
    "                        X=X,\n",
    "                        y=y,\n",
    "                        side=side,\n",
    "                        fitted_coef=self.coef_,\n",
    "                        full_loglik=self.loglik_,\n",
    "                        max_iter=self.pl_max_iter,\n",
    "                        max_stepsize=self.pl_max_stepsize,\n",
    "                        max_halfstep=self.pl_max_halfstep,\n",
    "                        tol=self.tol,\n",
    "                        alpha=0.05,\n",
    "                        jit=self.jit\n",
    "                    )\n",
    "                    for side in [-1, 1]\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # penalized likelihood ratio tests\n",
    "        if not self.skip_lrt:\n",
    "            pvals = []\n",
    "            # mask is 1-indexed because of `if mask` check in _get_XW()\n",
    "            for mask in range(1, self.coef_.shape[0] + 1):\n",
    "                _, null_loglik, _ = _firth_newton_raphson(\n",
    "                    X,\n",
    "                    y,\n",
    "                    self.max_iter,\n",
    "                    self.max_stepsize,\n",
    "                    self.max_halfstep,\n",
    "                    self.tol,\n",
    "                    mask,\n",
    "                    jit=self.jit\n",
    "                )\n",
    "                pvals.append(_lrt(self.loglik_, null_loglik))\n",
    "            self.pvals_ = np.array(pvals)\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = self.coef_[-1]\n",
    "            self.coef_ = self.coef_[:-1]\n",
    "        else:\n",
    "            self.intercept_ = 0\n",
    "\n",
    "        return self\n",
    "\n",
    "    def summary(self, xname=None, tablefmt=\"simple\"):\n",
    "        \"\"\"\n",
    "        Prints a summary table.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xname\n",
    "            Names for the X variables. Default is x1, x2, ... Must match the number of\n",
    "            parameters in the model.\n",
    "        tablefmt\n",
    "            `tabulate` table format for output. Please see the documentation for\n",
    "            `tabulate` for options.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        if xname and len(xname) != len(self.coef_):\n",
    "            raise ValueError(\n",
    "                f\"Length of xname ({len(xname)}) does not match the number of \"\n",
    "                f\"parameters in the model ({len(self.coef_)})\"\n",
    "            )\n",
    "\n",
    "        if not xname:\n",
    "            xname = [f\"x{i}\" for i in range(1, len(self.coef_) + 1)]\n",
    "\n",
    "        coef = list(self.coef_)\n",
    "        if self.fit_intercept:\n",
    "            xname.append(\"Intercept\")\n",
    "            coef.append(self.intercept_)\n",
    "\n",
    "        headers = [\n",
    "            \"\",\n",
    "            \"coef\",\n",
    "            \"std err\",\n",
    "            f\"[{self.alpha/2}\",\n",
    "            f\"{1-self.alpha/2}]\",\n",
    "            \"p-value\",\n",
    "        ]\n",
    "        table = zip(xname, coef, self.bse_, self.ci_[:, 0], self.ci_[:, 1], self.pvals_)\n",
    "        table = tabulate(table, headers, tablefmt=tablefmt)\n",
    "        table += \"\\n\\n\"\n",
    "        table += f\"Log-Likelihood: {round(self.loglik_, 4)}\\n\"\n",
    "        table += f\"Newton-Raphson iterations: {self.n_iter_}\\n\"\n",
    "        print(table)\n",
    "        return table\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = self._validate_data(X, reset=False)\n",
    "        scores = X @ self.coef_ + self.intercept_\n",
    "        return scores\n",
    "\n",
    "    def predict(self, X):\n",
    "        decision = self.decision_function(X)\n",
    "        if len(decision.shape) == 1:\n",
    "            indices = (decision > 0).astype(int)\n",
    "        else:\n",
    "            indices = decision.argmax(axis=1)\n",
    "        return self.classes_[indices]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        decision = self.decision_function(X)\n",
    "        if decision.ndim == 1:\n",
    "            decision = np.c_[-decision, decision]\n",
    "        proba = expit(decision)\n",
    "        return proba\n",
    "\n",
    "\n",
    "def _firth_newton_raphson(X, y, max_iter, max_stepsize, max_halfstep, tol, mask=None, jit=False):\n",
    "    # see logistf reference manual for explanation of procedure\n",
    "    coef = np.zeros(X.shape[1])\n",
    "    for iter in range(1, max_iter + 1):\n",
    "        preds = expit(X @ coef)\n",
    "        XW = _get_XW(X, preds, mask)\n",
    "\n",
    "        fisher_info_mtx = XW.T @ XW\n",
    "        hat = _hat_diag(XW)\n",
    "        U_star = np.matmul(X.T, y - preds + np.multiply(hat, 0.5 - preds))\n",
    "        step_size = np.linalg.lstsq(fisher_info_mtx, U_star, rcond=None)[0]\n",
    "        # if mask:\n",
    "        #     step_size[mask] = 0\n",
    "\n",
    "        # step-halving\n",
    "        mx = np.max(np.abs(step_size)) / max_stepsize\n",
    "        if mx > 1:\n",
    "            step_size = step_size / mx  # restrict to max_stepsize\n",
    "        coef_new = coef + step_size\n",
    "        preds_new = expit(X @ coef_new)\n",
    "        loglike = _loglikelihood(X, y, preds, jit)\n",
    "        loglike_new = _loglikelihood(X, y, preds_new, jit)\n",
    "        steps = 0\n",
    "        while loglike < loglike_new:\n",
    "            step_size *= 0.5\n",
    "            coef_new = coef + step_size\n",
    "            preds_new = expit(X @ coef_new)\n",
    "            loglike_new = _loglikelihood(X, y, preds_new, jit)\n",
    "            steps += 1\n",
    "            if steps == max_halfstep:\n",
    "                warning_msg = \"Step-halving failed to converge.\"\n",
    "                warnings.warn(warning_msg, ConvergenceWarning, stacklevel=2)\n",
    "                return coef_new, -loglike_new, iter\n",
    "\n",
    "        if iter > 1 and np.linalg.norm(coef_new - coef) < tol:\n",
    "            return coef_new, -loglike_new, iter\n",
    "\n",
    "        coef += step_size\n",
    "    warning_msg = (\n",
    "        \"Firth logistic regression failed to converge. Try increasing max_iter.\"\n",
    "    )\n",
    "    warnings.warn(warning_msg, ConvergenceWarning, stacklevel=2)\n",
    "    return coef, -loglike_new, max_iter\n",
    "\n",
    "\n",
    "def _loglikelihood(X, y, preds, jit):\n",
    "    # penalized log-likelihood\n",
    "    XW = _get_XW(X, preds)\n",
    "    fisher_info_mtx = XW.T @ XW\n",
    "    penalty = 0.5 * np.log(np.linalg.det(fisher_info_mtx))\n",
    "    if not jit:\n",
    "        return -1 * (np.sum(y * np.log(preds) + (1 - y) * np.log(1 - preds)) + penalty)\n",
    "    return -1 * (loglike_jit(y, preds) + penalty)\n",
    "\n",
    "def _get_XW(X, preds, mask=None):\n",
    "    # mask is 1-indexed because 0 == None\n",
    "    rootW = np.sqrt(preds * (1 - preds))\n",
    "    XW = rootW[:, np.newaxis] * X\n",
    "\n",
    "    # is this equivalent??\n",
    "    # https://github.com/georgheinze/logistf/blob/master/src/logistf.c#L150-L159\n",
    "    if mask:\n",
    "        XW[:, mask - 1] = 0\n",
    "    return XW\n",
    "\n",
    "\n",
    "def _get_aug_XW(X, preds, hats):\n",
    "    rootW = np.sqrt(preds * (1 - preds) * (1 + hats))\n",
    "    XW = rootW[:, np.newaxis] * X\n",
    "    return XW\n",
    "\n",
    "\n",
    "def _hat_diag(XW):\n",
    "    # Get diagonal elements of the hat matrix\n",
    "    # Q = np.linalg.qr(XW, mode=\"reduced\")[0]\n",
    "    qr, tau, _, _ = lapack.dgeqrf(XW)\n",
    "    Q, _, _ = lapack.dorgqr(qr, tau)\n",
    "    hat = np.einsum(\"ij,ij->i\", Q, Q)\n",
    "    return hat\n",
    "\n",
    "\n",
    "def _bse(X, coefs):\n",
    "    # se in logistf is diag(object$var) ^ 0.5, where var is the covariance matrix,\n",
    "    # which is the inverse of the observed fisher information matrix\n",
    "    # https://stats.stackexchange.com/q/68080/343314\n",
    "    preds = expit(X @ coefs)\n",
    "    XW = _get_XW(X, preds)\n",
    "    fisher_info_mtx = XW.T @ XW\n",
    "    return np.sqrt(np.diag(np.linalg.pinv(fisher_info_mtx)))\n",
    "\n",
    "\n",
    "def _lrt(full_loglik, null_loglik):\n",
    "    # in logistf: 1-pchisq(2*(fit.full$loglik-fit.i$loglik),1)\n",
    "    lr_stat = 2 * (full_loglik - null_loglik)\n",
    "    p_value = chi2.sf(lr_stat, df=1)\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def _predict(X, coef):\n",
    "    preds = expit(X @ coef)\n",
    "    np.clip(preds, a_min=1e-15, a_max=1 - 1e-15, out=preds)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def _profile_likelihood_ci(\n",
    "    X,\n",
    "    y,\n",
    "    side,\n",
    "    fitted_coef,\n",
    "    full_loglik,\n",
    "    max_iter,\n",
    "    max_stepsize,\n",
    "    max_halfstep,\n",
    "    tol,\n",
    "    alpha,\n",
    "    jit\n",
    "):\n",
    "    LL0 = full_loglik - chi2.ppf(1 - alpha, 1) / 2\n",
    "    ci = []\n",
    "    for coef_idx in range(fitted_coef.shape[0]):\n",
    "        coef = deepcopy(fitted_coef)\n",
    "        for iter in range(1, max_iter + 1):\n",
    "            # preds = expit(X @ coef)\n",
    "            preds = _predict(X, coef)\n",
    "            loglike = -_loglikelihood(X, y, preds, jit)\n",
    "            XW = _get_XW(X, preds)\n",
    "            hat = _hat_diag(XW)\n",
    "            XW = _get_aug_XW(X, preds, hat)  # augmented data using hat diag\n",
    "            fisher_info_mtx = XW.T @ XW\n",
    "            U_star = np.matmul(X.T, y - preds + np.multiply(hat, 0.5 - preds))\n",
    "            # https://github.com/georgheinze/logistf/blob/master/src/logistf.c#L780-L781\n",
    "            inv_fisher = np.linalg.pinv(fisher_info_mtx)\n",
    "            tmp1x1 = U_star @ np.negative(inv_fisher) @ U_star\n",
    "            underRoot = (\n",
    "                -2 * ((LL0 - loglike) + 0.5 * tmp1x1) / (inv_fisher[coef_idx, coef_idx])\n",
    "            )\n",
    "            lambda_ = 0 if underRoot < 0 else side * sqrt(underRoot)\n",
    "            U_star[coef_idx] += lambda_\n",
    "\n",
    "            step_size = np.linalg.lstsq(fisher_info_mtx, U_star, rcond=None)[0]\n",
    "            mx = np.max(np.abs(step_size)) / max_stepsize\n",
    "            if mx > 1:\n",
    "                step_size = step_size / mx  # restrict to max_stepsize\n",
    "            coef += step_size\n",
    "            loglike_old = deepcopy(loglike)\n",
    "\n",
    "            for halfs in range(1, max_halfstep + 1):\n",
    "                # preds = expit(X @ coef)\n",
    "                preds = _predict(X, coef)\n",
    "                loglike = -_loglikelihood(X, y, preds, jit)\n",
    "                if (abs(loglike - LL0) < abs(loglike_old - LL0)) and loglike > LL0:\n",
    "                    break\n",
    "                step_size *= 0.5\n",
    "                coef -= step_size\n",
    "            if abs(loglike - LL0) <= tol:\n",
    "                ci.append(coef[coef_idx])\n",
    "                break\n",
    "        if abs(loglike - LL0) > tol:\n",
    "            ci.append(np.nan)\n",
    "            warning_msg = (\n",
    "                f\"Non-converged PL confidence limits - max number of \"\n",
    "                f\"iterations exceeded for variable x{coef_idx}. Try \"\n",
    "                f\"increasing pl_max_iter.\"\n",
    "            )\n",
    "            warnings.warn(warning_msg, ConvergenceWarning, stacklevel=2)\n",
    "    return ci\n",
    "\n",
    "\n",
    "def load_sex2():\n",
    "    \"\"\"\n",
    "    Load the sex2 dataset from `logistf`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X\n",
    "        sex2 data as numpy array\n",
    "    y\n",
    "        sex2 `case` target column\n",
    "    feature_names\n",
    "        List of feature names\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Cytel Inc., (2010) LogXact 9 user manual, Cambridge, MA:Cytel Inc\n",
    "    \"\"\"\n",
    "    with open_text(\"firthlogist.datasets\", \"sex2.csv\") as sex2:\n",
    "        X = np.loadtxt(sex2, skiprows=1, delimiter=\",\")\n",
    "    y = X[:, 0]\n",
    "    X = X[:, 1:]\n",
    "    feature_names = [\"age\", \"oc\", \"vic\", \"vicl\", \"vis\", \"dia\"]\n",
    "    return X, y, feature_names\n",
    "\n",
    "\n",
    "def load_endometrial():\n",
    "    \"\"\"\n",
    "    Load the endometrial cancer dataset analyzed in Heinze and Schemper (2002). The data\n",
    "    was originally provided by Dr E. Asseryanis from the Vienna University Medical\n",
    "    School\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X\n",
    "        endometrial data as numpy array\n",
    "    y\n",
    "        endometrial `HG` target column\n",
    "    feature_names\n",
    "        List of feature names\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Agresti, A (2015). Foundations of Linear and Generalized Linear Models.\n",
    "    Wiley Series in Probability and Statistics.\n",
    "\n",
    "    Heinze G, Schemper M (2002). A solution to the problem of separation in logistic\n",
    "    regression. Statistics in Medicine 21: 2409-2419.\n",
    "    \"\"\"\n",
    "    with open_text(\"firthlogist.datasets\", \"endometrial.csv\") as sex2:\n",
    "        X = np.loadtxt(sex2, skiprows=1, delimiter=\",\")\n",
    "    y = X[:, -1]\n",
    "    X = X[:, :-1]\n",
    "    feature_names = [\"NV\", \"PI\", \"EH\"]\n",
    "    return X, y, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95ca2b48-8740-4548-a957-67acab1abc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  coef    std err       [0.025       0.975]       p-value\n",
      "---------  -----------  ---------  -----------  -----------  ------------\n",
      "x1          -0.195116   0.0866002   -0.366847    -0.0259218  0.021921\n",
      "x2          -0.421939   0.0381293   -0.497584    -0.347674   2.29921e-30\n",
      "x3          -0.426402   0.0961199   -0.616994    -0.238286   7.67488e-06\n",
      "x4           0.176908   0.0514913    0.0758403    0.278311   0.00055621\n",
      "x5           0.33899    0.0820833    0.178098     0.501285   3.39404e-05\n",
      "x6           0.978589   0.0784099    0.825111     1.13497    1.2355e-38\n",
      "x7          -0.0481063  0.0732158   -0.193543     0.0952611  0.503734\n",
      "x8          -0.331244   0.0521999   -0.436036    -0.22988    3.09936e-11\n",
      "x9           1.13453    0.0528053    1.03265      1.24074    1.80347e-161\n",
      "x10          0.868236   0.0472195    0.777148     0.963157   4.02882e-109\n",
      "x11          0.0504533  0.0716943   -0.0909186    0.192164   0.479054\n",
      "x12          0.0844147  0.052282    -0.0189676    0.18745    0.106101\n",
      "x13         -0.326686   0.0652638   -0.457229    -0.200087   2.284e-07\n",
      "x14          0.0277992  0.0699818   -0.11067      0.16515    0.667722\n",
      "x15          1.33233    0.0519161    1.23267      1.43737    1.21027e-283\n",
      "x16         -0.508203   0.0490172   -0.605543    -0.412165   1.30204e-25\n",
      "Intercept  -25.5656     1.69047    -28.9468     -22.2769     1.73529e-66\n",
      "\n",
      "Log-Likelihood: -866.5766\n",
      "Newton-Raphson iterations: 11\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'                  coef    std err       [0.025       0.975]       p-value\\n---------  -----------  ---------  -----------  -----------  ------------\\nx1          -0.195116   0.0866002   -0.366847    -0.0259218  0.021921\\nx2          -0.421939   0.0381293   -0.497584    -0.347674   2.29921e-30\\nx3          -0.426402   0.0961199   -0.616994    -0.238286   7.67488e-06\\nx4           0.176908   0.0514913    0.0758403    0.278311   0.00055621\\nx5           0.33899    0.0820833    0.178098     0.501285   3.39404e-05\\nx6           0.978589   0.0784099    0.825111     1.13497    1.2355e-38\\nx7          -0.0481063  0.0732158   -0.193543     0.0952611  0.503734\\nx8          -0.331244   0.0521999   -0.436036    -0.22988    3.09936e-11\\nx9           1.13453    0.0528053    1.03265      1.24074    1.80347e-161\\nx10          0.868236   0.0472195    0.777148     0.963157   4.02882e-109\\nx11          0.0504533  0.0716943   -0.0909186    0.192164   0.479054\\nx12          0.0844147  0.052282    -0.0189676    0.18745    0.106101\\nx13         -0.326686   0.0652638   -0.457229    -0.200087   2.284e-07\\nx14          0.0277992  0.0699818   -0.11067      0.16515    0.667722\\nx15          1.33233    0.0519161    1.23267      1.43737    1.21027e-283\\nx16         -0.508203   0.0490172   -0.605543    -0.412165   1.30204e-25\\nIntercept  -25.5656     1.69047    -28.9468     -22.2769     1.73529e-66\\n\\nLog-Likelihood: -866.5766\\nNewton-Raphson iterations: 11\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('../letter_img_X.npy')\n",
    "y = np.load('../letter_img_y.npy')\n",
    "fl_jit = FirthLogisticRegression(jit=True)\n",
    "fl_nojit = FirthLogisticRegression(jit=False)\n",
    "fl_nojit.fit(X, y)\n",
    "fl_nojit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2fffb8f6-ec77-4d19-8190-09036beeb2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.02 s ± 108 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.28 s ± 228 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fl_jit.fit(X, y)\n",
    "%timeit fl_nojit.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42ecdfb5-0796-4d65-a4c1-23fb6db8b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11 s ± 147 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.03 s ± 71.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fl_jit.fit(X, y)\n",
    "%timeit fl_nojit.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6623794-a33d-499b-9ae8-d84e2468f510",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _get_XW(X, preds, mask=None):\n",
    "    # mask is 1-indexed because 0 == None\n",
    "    rootW = np.sqrt(preds * (1 - preds))\n",
    "    XW = rootW[..., np.newaxis] * X\n",
    "\n",
    "    # is this equivalent??\n",
    "    # https://github.com/georgheinze/logistf/blob/master/src/logistf.c#L150-L159\n",
    "    if mask:\n",
    "        XW[:, mask - 1] = 0\n",
    "    return XW\n",
    "\n",
    "def _get_aug_XW(X, preds, tau, h_diag):\n",
    "    # mask is 1-indexed because 0 == None\n",
    "#     rootW = np.sqrt(preds * (1 - preds) * (1 + 2 * tau * h_diag))\n",
    "    rootW = np.sqrt(preds * (1 - preds) * (1 + h_diag))\n",
    "#     rootW = np.sqrt(preds * (1 - preds))\n",
    "    XW = rootW[..., np.newaxis] * X\n",
    "    \n",
    "    \n",
    "    return XW\n",
    "\n",
    "def _get_aug_XW_jon(X, preds, hats):\n",
    "    rootW = np.sqrt(preds * (1 - preds) * (1 + hats))\n",
    "    XW = rootW[:, np.newaxis] * X\n",
    "    return XW\n",
    "\n",
    "\n",
    "def _hat_diag(XW):\n",
    "    # Get diagonal elements of the hat matrix\n",
    "    # Q = np.linalg.qr(XW, mode=\"reduced\")[0]\n",
    "    qr, tau, _, _ = lapack.dgeqrf(XW)\n",
    "    Q, _, _ = lapack.dorgqr(qr, tau)\n",
    "    hat = np.einsum(\"ij,ij->i\", Q, Q)\n",
    "    return hat\n",
    "\n",
    "def _loglikelihood(X, y, preds):\n",
    "    # penalized log-likelihood\n",
    "    XW = _get_XW(X, preds)\n",
    "    fisher_info_mtx = XW.T @ XW\n",
    "    penalty = 0.5 * np.log(np.linalg.det(fisher_info_mtx))\n",
    "    return -1 * (np.sum(y * np.log(preds) + (1 - y) * np.log(1 - preds)) + penalty)\n",
    "\n",
    "def _get_preds(X, coef):\n",
    "    return expit(X @ coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8cebc-a8b1-4d4c-a8df-02809ab11e26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sex2 = pd.read_csv('tests/sex2.csv')\n",
    "# diabetes = pd.read_csv('tests/diabetes.csv')\n",
    "# diabetes.insert(0, 'intercept', np.repeat(1, diabetes.shape[0]))\n",
    "X = sex2.iloc[:, 1:].values\n",
    "y = sex2['case'].values\n",
    "# X = diabetes.iloc[:, :-1].values\n",
    "# y = diabetes['Outcome'].values\n",
    "firth = FirthLogisticRegression()\n",
    "firth.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e79e0f8-98bd-4a5b-a156-0116351a46ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "coef = np.array([firth.intercept_, *firth.coef_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edb20457-ab06-4e33-8809-d7e7e8f0a4ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = X.shape[1]\n",
    "n = X.shape[0]\n",
    "which = -1\n",
    "iSel = 1\n",
    "tol = firth.tol\n",
    "tau = 0.5\n",
    "alpha = 0.05\n",
    "max_halfstep = 1000\n",
    "max_stepsize = 5\n",
    "max_iter = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31ae5180-e493-41d8-9cc1-81c2c07bd9df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-132.5393795328482"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization\n",
    "LL0 = firth.loglik_ - (chi2.ppf(1 - alpha, 1) / 2)\n",
    "preds = _get_preds(X, coef)\n",
    "loglik = -_loglikelihood(X, y, preds)\n",
    "loglik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df5739-536e-45c2-bf03-fe1c8630311a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a44a299e-ba1f-4bda-873d-f4b0a1f1a503",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calc XW^1/2\n",
    "xw2 = _get_XW(X, preds).T\n",
    "fisher_info_matrix = xw2 @ xw2.T\n",
    "log_fisher_det = np.log(np.linalg.det(fisher_info_matrix))\n",
    "fisher_inv = np.linalg.inv(fisher_info_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79138ba3-0686-4ea3-9fe3-56bfd7079657",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calc hat diag and loglikelihood\n",
    "tmpNxK = xw2.T @ fisher_inv\n",
    "# This looks correct\n",
    "h_diag = np.diag(tmpNxK @ xw2)\n",
    "h_diag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "652ac8ac-cb41-4f89-97a9-26ba51c729a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the augmented data using hat diag (lines 753-759 in C code)\n",
    "xw2_aug = _get_aug_XW(X, preds, tau, h_diag).T\n",
    "fisher_aug = xw2_aug @ xw2_aug.T\n",
    "fisher_aug_det = np.log(np.linalg.det(fisher_aug))\n",
    "fisher_aug_inv = np.linalg.inv(fisher_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcf0d1b4-7957-4e5e-954b-a8e05851b464",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47334627, 0.27739598, 0.27739598, ..., 0.42014777, 0.36321753,\n",
       "        0.36321753],\n",
       "       [0.        , 0.        , 0.        , ..., 0.42014777, 0.36321753,\n",
       "        0.36321753],\n",
       "       [0.        , 0.        , 0.        , ..., 0.42014777, 0.36321753,\n",
       "        0.36321753],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.36321753,\n",
       "        0.36321753],\n",
       "       [0.47334627, 0.        , 0.        , ..., 0.        , 0.36321753,\n",
       "        0.36321753],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xw2_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebcc78c7-6430-428c-aaa1-cf7417512079",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7047a209-e316-4d05-9735-485a63409bcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67250885, 0.07458449, 0.07458449, 0.07458449, 0.07458449])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the new weights\n",
    "w = (y - preds) + 2 * tau * h_diag * (0.5 - preds)\n",
    "w[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "012e4c97-3d75-4ebe-bfc1-c9f1fc9cfc13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.99780044e-06  1.94686835e-06 -1.47840247e-07  2.15588820e-06\n",
      "  2.28431038e-06  2.07192717e-06  1.81926204e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-9.43491787769868e-12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calc Ustar and lambda values\n",
    "Ustar = X.T @ w\n",
    "print(Ustar)\n",
    "fisher_inv = -fisher_aug_inv.copy()\n",
    "tmpKx1 = Ustar.T @ fisher_inv\n",
    "tmp1x1 = tmpKx1.T @ Ustar\n",
    "tmp1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbd77eee-0edf-4491-9a4d-837f365555ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.179487905010124"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher_aug_inv[iSel, iSel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d94ed6fa-babe-43cb-8be9-d860486121b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.402326917164384\n",
      "-4.626264899156163\n"
     ]
    }
   ],
   "source": [
    "under_root = -2 * ((LL0 - loglik) + 0.5 * tmp1x1) / fisher_aug_inv[iSel, iSel]\n",
    "print(under_root)\n",
    "lambda_ = 0 if under_root < 0 else which * np.sqrt(under_root)\n",
    "print(lambda_)\n",
    "Ustar[iSel] = Ustar[iSel] + lambda_\n",
    "step_size = fisher_aug_inv.T @ Ustar\n",
    "if max_halfstep >= 0:\n",
    "    mx = np.max(np.abs(step_size)) / max_halfstep\n",
    "    if mx > 1:\n",
    "        step_size = step_size / mx\n",
    "new_coef = coef + step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b28d08f0-8632-4656-9356-caf05f6d1939",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12688378, -0.83035839, -0.00841051,  0.10717171, -0.16004898,\n",
       "       -0.0033202 ,  0.30335563])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d1a6336-0c51-420d-90ed-e9062fc1e04f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loglik_old = loglik.copy()\n",
    "for halfs in range(1, max_halfstep + 1):\n",
    "    new_preds = _get_preds(X, new_coef)\n",
    "    xw2 = _get_XW(X, new_preds).T\n",
    "    loglik = -_loglikelihood(X, y, new_preds)\n",
    "    fisher_info_matrix = xw2 @ xw2.T\n",
    "    fisher_det = np.linalg.det(fisher_info_matrix)\n",
    "    fisher_inv = np.linalg.inv(fisher_info_matrix)\n",
    "    # Calc hat diag and loglikelihood\n",
    "    tmpNxK = xw2.T @ fisher_inv\n",
    "    h_diag = np.diagonal(tmpNxK @ xw2)\n",
    "    loglik = -_loglikelihood(X, y, new_preds)\n",
    "    # Get augmented data\n",
    "    xw2_aug = _get_aug_XW(X, new_preds, tau, h_diag).T\n",
    "    fisher_aug = xw2_aug @ xw2_aug.T\n",
    "    fisher_aug_det = np.linalg.det(fisher_aug)\n",
    "    fisher_aug = np.linalg.inv(fisher_aug)\n",
    "    if (abs(loglik - LL0) < abs(loglik_old - LL0)) and (loglik > LL0):\n",
    "        print(halfs, 'broken out of loop')\n",
    "        break\n",
    "    step_size /= 2\n",
    "    new_coef -= step_size\n",
    "if abs(loglik - LL0) <= tol:\n",
    "    print(new_coef[iSel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16b0c886-53df-493f-bdec-a02053e4b02c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.18416015e-302, -7.74943275e-302, -7.84922730e-304,\n",
       "        1.00019462e-302, -1.49367890e-302, -3.09862069e-304,\n",
       "        2.83110773e-302])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793ac4e-ecb1-4c48-8095-f9ad32b9eabb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Iteration To Max Iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee685e73-4e23-4d94-aef1-e20462c0ca83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sex2 = pd.read_csv('tests/sex2.csv')\n",
    "diabetes = pd.read_csv('tests/diabetes.csv')\n",
    "# diabetes.insert(0, 'intercept', np.repeat(1, diabetes.shape[0]))\n",
    "X = sex2.iloc[:, 1:].values\n",
    "y = sex2['case'].values\n",
    "# X = diabetes.iloc[:, :-1].values\n",
    "# y = diabetes['Outcome'].values\n",
    "firth = FirthLogisticRegression()\n",
    "firth.fit(X, y)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d1512b2-9bb2-441d-8ce8-2f5e3fe9311c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "iris = sklearn.datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "y = np.where(y == y.flat[0], y, y.flat[0] + 1)\n",
    "firth = FirthLogisticRegression(skip_ci=True, max_iter=100)\n",
    "firth.fit(X, y)\n",
    "firth.coef_\n",
    "firth.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba6e7227-ef3e-46c2-bcd9-4d7c53c5547d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=['x0','x1','x2','x3'])\n",
    "df['y'] = y\n",
    "df.to_csv('iris.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7722b3fc-040d-4326-8cde-370de7178e2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff9d9445-b17a-4227-8937-1d4cb0b10eb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02162242, -6.99849918, 11.14813559,  5.15488554]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='none')\n",
    "lr.fit(X, y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc1f8a29-c42f-4d7e-b60d-fb412620b4f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# coef = np.array([firth.intercept_, *firth.coef_])\n",
    "# X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "coef = np.array([*firth.coef_, firth.intercept_])\n",
    "X = np.hstack((X, np.ones((X.shape[0], 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "161b3f98-f19b-42ca-81ad-a5997a5933d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = X.shape[1]\n",
    "n = X.shape[0]\n",
    "# which = -1 -> lower bounds, which = 1 -> upper bounds\n",
    "which = -1\n",
    "tol = firth.tol\n",
    "tau = 0.5\n",
    "alpha = 0.05\n",
    "max_halfstep = 1000\n",
    "max_stepsize = 5\n",
    "max_iter = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b339b60f-62dd-4a96-b94a-8147dad1236b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.337338455265538"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firth.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "915e522c-df6e-4dfd-83d3-c70295119e56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1cc3e2c-0bba-40eb-957e-d3e7b66dfa95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lower_bds = []\n",
    "upper_bds = []\n",
    "for i in range(1, k):\n",
    "    iSel = i\n",
    "    LL0 = firth.loglik_ - (chi2.ppf(1 - alpha, 1) / 2)\n",
    "    coef = np.array([*firth.coef_, firth.intercept_])\n",
    "\n",
    "    for iter_ in range(1, max_iter + 1):\n",
    "        # Initialization\n",
    "\n",
    "        preds = _get_preds(X, coef)\n",
    "        loglik = -_loglikelihood(X, y, preds)\n",
    "#         print(f'loglik = {loglik}')\n",
    "        # print(f'{iter_=}')\n",
    "        # calc XW^1/2\n",
    "        xw2 = _get_XW(X, preds).T\n",
    "        fisher_info_matrix = xw2 @ xw2.T\n",
    "        log_fisher_det = np.log(np.linalg.det(fisher_info_matrix))\n",
    "        fisher_inv = np.linalg.inv(fisher_info_matrix)\n",
    "\n",
    "        # Calc hat diag and loglikelihood\n",
    "        tmpNxK = xw2.T @ fisher_inv\n",
    "        # This looks correct\n",
    "        h_diag = np.diag(tmpNxK @ xw2)\n",
    "\n",
    "        # Get the augmented data using hat diag (lines 753-759 in C code)\n",
    "        xw2_aug = _get_aug_XW(X, preds, tau, h_diag).T\n",
    "        fisher_aug = xw2_aug @ xw2_aug.T\n",
    "        fisher_aug_det = np.log(np.linalg.det(fisher_aug))\n",
    "        fisher_aug_inv = np.linalg.inv(fisher_aug)\n",
    "#         print(xw2_aug.T)\n",
    "        # calc the new weights\n",
    "        w = (y - preds) + 2 * tau * h_diag * (0.5 - preds)\n",
    "        Ustar = X.T @ w\n",
    "        # print(f'{Ustar=}')\n",
    "        fisher_inv = -fisher_aug_inv.copy()\n",
    "        tmpKx1 = Ustar.T @ fisher_inv\n",
    "        tmp1x1 = tmpKx1.T @ Ustar\n",
    "#         print(Ustar)\n",
    "#         print(fisher_inv)\n",
    "#         print(Ustar)\n",
    "#         print(f'{tmp1x1=}')\n",
    "        # print(f'fisher_augmented = {fisher_aug_inv[iSel, iSel]}')\n",
    "        under_root = -2 * ((LL0 - loglik) + 0.5 * tmp1x1) / fisher_aug_inv[iSel, iSel]\n",
    "#         print(f'{under_root=}')\n",
    "#         print((LL0 - loglik) + 0.5 * tmp1x1)\n",
    "        lambda_ = 0 if under_root < 0 else which * np.sqrt(under_root)\n",
    "#         print(f'{lambda_=}')\n",
    "        Ustar[iSel] = Ustar[iSel] + lambda_\n",
    "        step_size = fisher_aug_inv.T @ Ustar\n",
    "        if max_halfstep >= 0:\n",
    "            mx = np.max(np.abs(step_size)) / max_halfstep\n",
    "            if mx > 1:\n",
    "                step_size = step_size / mx\n",
    "#         print(f'step_size={[x for x in step_size]}\\n')\n",
    "#         print('coef_old', coef)\n",
    "        coef = coef + step_size\n",
    "#         print('coef', coef)\n",
    "        # Iterate over halfsteps\n",
    "        loglik_old = loglik.copy()\n",
    "        for halfs in range(1, max_halfstep + 1):\n",
    "            preds = _get_preds(X, coef)\n",
    "            xw2 = _get_XW(X, preds).T\n",
    "            loglik = -_loglikelihood(X, y, preds)\n",
    "            fisher_info_matrix = xw2 @ xw2.T\n",
    "            fisher_det = np.linalg.det(fisher_info_matrix)\n",
    "            fisher_inv = np.linalg.inv(fisher_info_matrix)\n",
    "            # Calc hat diag and loglikelihood\n",
    "            tmpNxK = xw2.T @ fisher_inv\n",
    "            h_diag = np.diagonal(tmpNxK @ xw2)\n",
    "            loglik = -_loglikelihood(X, y, preds)\n",
    "            # Get augmented data\n",
    "            xw2_aug = _get_aug_XW(X, preds, tau, h_diag).T\n",
    "            fisher_aug = xw2_aug @ xw2_aug.T\n",
    "            fisher_aug_det = np.linalg.det(fisher_aug)\n",
    "            fisher_aug = np.linalg.inv(fisher_aug)\n",
    "#             print('loglik-ll0=', abs(loglik-LL0))\n",
    "            if (abs(loglik - LL0) < abs(loglik_old - LL0)) and (loglik > LL0):\n",
    "                break\n",
    "            step_size /= 2\n",
    "            coef -= step_size\n",
    "#             print('posths_coef', coef)\n",
    "        if abs(loglik - LL0) <= tol:\n",
    "            lower_bds.append(coef[iSel])\n",
    "            break\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c56807e5-88ca-43cc-8395-df88aa3f69d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-14.915308156930347]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f2205d7-e1ac-4451-a0e0-9af189ba5812",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.8185450801110972,\n",
       " -1.9737883819057844,\n",
       " -0.941424219446236,\n",
       " 1.2730351899978471,\n",
       " -3.260839223819344,\n",
       " -1.608086648992101,\n",
       " 0.7746070226955406]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff52791b-0237-428b-9ecb-660e70492a5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootW_h = np.sqrt(preds * (1 - preds) * (1 + 2 * tau * 0))\n",
    "rootW = np.sqrt(preds * (1 - preds))\n",
    "np.allclose(rootW, rootW_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "140e57d8-8454-4425-8751-68d2d2f7632f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 + 2 * tau * -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:firth]",
   "language": "python",
   "name": "conda-env-firth-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
