{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5295e218-84b9-4b31-8fcc-95f6c71d69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lapack\n",
    "from scipy.special import expit\n",
    "from scipy.stats import chi2\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from firthlogist import FirthLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b6623794-a33d-499b-9ae8-d84e2468f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_XW(X, preds, mask=None):\n",
    "    # mask is 1-indexed because 0 == None\n",
    "    rootW = np.sqrt(preds * (1 - preds))\n",
    "    XW = rootW[..., np.newaxis] * X\n",
    "\n",
    "    # is this equivalent??\n",
    "    # https://github.com/georgheinze/logistf/blob/master/src/logistf.c#L150-L159\n",
    "    if mask:\n",
    "        XW[:, mask - 1] = 0\n",
    "    return XW\n",
    "\n",
    "def _get_aug_XW(X, preds, tau, h_diag):\n",
    "    # mask is 1-indexed because 0 == None\n",
    "    rootW = np.sqrt(preds * (1 - preds) * (1 + 2 * tau * h_diag))\n",
    "    XW = rootW[..., np.newaxis] * X\n",
    "    \n",
    "    \n",
    "    return XW\n",
    "\n",
    "def _hat_diag(XW):\n",
    "    # Get diagonal elements of the hat matrix\n",
    "    # Q = np.linalg.qr(XW, mode=\"reduced\")[0]\n",
    "    qr, tau, _, _ = lapack.dgeqrf(XW)\n",
    "    Q, _, _ = lapack.dorgqr(qr, tau)\n",
    "    hat = np.einsum(\"ij,ij->i\", Q, Q)\n",
    "    return hat\n",
    "\n",
    "def _loglikelihood(X, y, preds):\n",
    "    # penalized log-likelihood\n",
    "    XW = _get_XW(X, preds)\n",
    "    fisher_info_mtx = XW.T @ XW\n",
    "    penalty = 0.5 * np.log(np.linalg.det(fisher_info_mtx))\n",
    "    return -1 * (np.sum(y * np.log(preds) + (1 - y) * np.log(1 - preds)) + penalty)\n",
    "\n",
    "def _get_preds(X, coef):\n",
    "    return expit(X @ coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "fbf8cebc-a8b1-4d4c-a8df-02809ab11e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FirthLogisticRegression()"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex2 = pd.read_csv('tests/sex2.csv')\n",
    "diabetes = pd.read_csv('tests/diabetes.csv')\n",
    "# diabetes.insert(0, 'intercept', np.repeat(1, diabetes.shape[0]))\n",
    "# X = sex2.iloc[:, 1:].values\n",
    "# y = sex2['case'].values\n",
    "X = diabetes.iloc[:, :-1].values\n",
    "y = diabetes['Outcome'].values\n",
    "firth = FirthLogisticRegression()\n",
    "firth.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "4e79e0f8-98bd-4a5b-a156-0116351a46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "coef = np.array([firth.intercept_, *firth.coef_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "edb20457-ab06-4e33-8809-d7e7e8f0a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = X.shape[1]\n",
    "n = X.shape[0]\n",
    "which = -1\n",
    "iSel = 1\n",
    "tol = firth.tol\n",
    "tau = 0.5\n",
    "alpha = 0.05\n",
    "max_halfstep = 1000\n",
    "max_stepsize = 5\n",
    "max_iter = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "31ae5180-e493-41d8-9cc1-81c2c07bd9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "LL0 = firth.loglik_ - (chi2.ppf(1 - alpha, 1) / 2)\n",
    "preds = _get_preds(X, coef)\n",
    "loglik = -_loglikelihood(X, y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df5739-536e-45c2-bf03-fe1c8630311a",
   "metadata": {},
   "source": [
    "# First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "a44a299e-ba1f-4bda-873d-f4b0a1f1a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc XW^1/2\n",
    "xw2 = _get_XW(X, preds).T\n",
    "fisher_info_matrix = xw2 @ xw2.T\n",
    "log_fisher_det = np.log(np.linalg.det(fisher_info_matrix))\n",
    "fisher_inv = np.linalg.inv(fisher_info_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "79138ba3-0686-4ea3-9fe3-56bfd7079657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239,)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calc hat diag and loglikelihood\n",
    "tmpNxK = xw2.T @ fisher_inv\n",
    "# This looks correct\n",
    "h_diag = np.diag(tmpNxK @ xw2)\n",
    "h_diag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "652ac8ac-cb41-4f89-97a9-26ba51c729a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the augmented data using hat diag (lines 753-759 in C code)\n",
    "xw2_aug = _get_aug_XW(X, preds, tau, h_diag).T\n",
    "fisher_aug = xw2_aug @ xw2_aug.T\n",
    "fisher_aug_det = np.log(np.linalg.det(fisher_aug))\n",
    "fisher_aug_inv = np.linalg.inv(fisher_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "7047a209-e316-4d05-9735-485a63409bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67250885, 0.07458449, 0.07458449, 0.07458449, 0.07458449])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the new weights\n",
    "w = (y - preds) + 2 * tau * h_diag * (0.5 - preds)\n",
    "w[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "012e4c97-3d75-4ebe-bfc1-c9f1fc9cfc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.99780046e-06  1.94686835e-06 -1.47840235e-07  2.15588817e-06\n",
      "  2.28431037e-06  2.07192716e-06  1.81926203e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-7.551333525013887e-12"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calc Ustar and lambda values\n",
    "Ustar = X.T @ w\n",
    "print(Ustar)\n",
    "fisher_inv = -fisher_aug_inv.copy()\n",
    "tmpKx1 = Ustar.T @ fisher_inv\n",
    "tmp1x1 = tmpKx1.T @ Ustar\n",
    "tmp1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "cbd77eee-0edf-4491-9a4d-837f365555ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1721437593189589"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher_aug_inv[iSel, iSel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d94ed6fa-babe-43cb-8be9-d860486121b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.31541146713301\n",
      "-4.723919079232096\n"
     ]
    }
   ],
   "source": [
    "under_root = -2 * ((LL0 - loglik) + 0.5 * tmp1x1) / fisher_aug_inv[iSel, iSel]\n",
    "print(under_root)\n",
    "lambda_ = 0 if under_root < 0 else which * np.sqrt(under_root)\n",
    "print(lambda_)\n",
    "Ustar[iSel] = Ustar[iSel] + lambda_\n",
    "step_size = fisher_aug_inv.T @ Ustar\n",
    "if max_halfstep >= 0:\n",
    "    mx = np.max(np.abs(step_size)) / max_halfstep\n",
    "    if mx > 1:\n",
    "        step_size = step_size / mx\n",
    "new_coef = coef + step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "b28d08f0-8632-4656-9356-caf05f6d1939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12738916, -0.81319301, -0.0096957 ,  0.10875095, -0.16123714,\n",
       "       -0.00415691,  0.33766839])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7d1a6336-0c51-420d-90ed-e9062fc1e04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 broken out of loop\n"
     ]
    }
   ],
   "source": [
    "loglik_old = loglik.copy()\n",
    "for halfs in range(1, max_halfstep + 1):\n",
    "    new_preds = _get_preds(X, new_coef)\n",
    "    xw2 = _get_XW(X, new_preds).T\n",
    "    loglik = -_loglikelihood(X, y, new_preds)\n",
    "    fisher_info_matrix = xw2 @ xw2.T\n",
    "    fisher_det = np.linalg.det(fisher_info_matrix)\n",
    "    fisher_inv = np.linalg.inv(fisher_info_matrix)\n",
    "    # Calc hat diag and loglikelihood\n",
    "    tmpNxK = xw2.T @ fisher_inv\n",
    "    h_diag = np.diagonal(tmpNxK @ xw2)\n",
    "    loglik = -_loglikelihood(X, y, new_preds)\n",
    "    # Get augmented data\n",
    "    xw2_aug = _get_aug_XW(X, new_preds, tau, h_diag).T\n",
    "    fisher_aug = xw2_aug @ xw2_aug.T\n",
    "    fisher_aug_det = np.linalg.det(fisher_aug)\n",
    "    fisher_aug = np.linalg.inv(fisher_aug)\n",
    "    if (abs(loglik - LL0) < abs(loglik_old - LL0)) and (loglik > LL0):\n",
    "        print(halfs, 'broken out of loop')\n",
    "        break\n",
    "    step_size /= 2\n",
    "    new_coef -= step_size\n",
    "if abs(loglike - LL0) <= tol:\n",
    "    print(new_coef[iSel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "16b0c886-53df-493f-bdec-a02053e4b02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00398091, -0.02541228, -0.00030299,  0.00339847, -0.00503866,\n",
       "       -0.0001299 ,  0.01055208])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793ac4e-ecb1-4c48-8095-f9ad32b9eabb",
   "metadata": {},
   "source": [
    "# Iteration To Max Iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ee685e73-4e23-4d94-aef1-e20462c0ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex2 = pd.read_csv('tests/sex2.csv')\n",
    "diabetes = pd.read_csv('tests/diabetes.csv')\n",
    "# diabetes.insert(0, 'intercept', np.repeat(1, diabetes.shape[0]))\n",
    "# X = sex2.iloc[:, 1:].values\n",
    "# y = sex2['case'].values\n",
    "X = diabetes.iloc[:, :-1].values\n",
    "y = diabetes['Outcome'].values\n",
    "firth = FirthLogisticRegression()\n",
    "firth.fit(X, y)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "cc1f8a29-c42f-4d7e-b60d-fb412620b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coef = np.array([firth.intercept_, *firth.coef_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "161b3f98-f19b-42ca-81ad-a5997a5933d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = X.shape[1]\n",
    "n = X.shape[0]\n",
    "# which = -1 -> lower bounds, which = 1 -> upper bounds\n",
    "which = -1\n",
    "tol = firth.tol\n",
    "tau = 0.5\n",
    "alpha = 0.05\n",
    "max_halfstep = 1000\n",
    "max_stepsize = 5\n",
    "max_iter = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "a1cc3e2c-0bba-40eb-957e-d3e7b66dfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bds = []\n",
    "for i in range(k):\n",
    "    iSel = i\n",
    "    LL0 = firth.loglik_ - (chi2.ppf(1 - alpha, 1) / 2)\n",
    "    coef = np.array([firth.intercept_, *firth.coef_])\n",
    "    for iter_ in range(1, max_iter + 1):\n",
    "        # Initialization\n",
    "\n",
    "        preds = _get_preds(X, coef)\n",
    "        loglik = -_loglikelihood(X, y, preds)\n",
    "        # print(f'{iter_=}')\n",
    "        # calc XW^1/2\n",
    "        xw2 = _get_XW(X, preds).T\n",
    "        fisher_info_matrix = xw2 @ xw2.T\n",
    "        log_fisher_det = np.log(np.linalg.det(fisher_info_matrix))\n",
    "        fisher_inv = np.linalg.inv(fisher_info_matrix)\n",
    "\n",
    "        # Calc hat diag and loglikelihood\n",
    "        tmpNxK = xw2.T @ fisher_inv\n",
    "        # This looks correct\n",
    "        h_diag = np.diag(tmpNxK @ xw2)\n",
    "\n",
    "        # Get the augmented data using hat diag (lines 753-759 in C code)\n",
    "        xw2_aug = _get_aug_XW(X, preds, tau, h_diag).T\n",
    "        fisher_aug = xw2_aug @ xw2_aug.T\n",
    "        fisher_aug_det = np.log(np.linalg.det(fisher_aug))\n",
    "        fisher_aug_inv = np.linalg.inv(fisher_aug)\n",
    "\n",
    "        # calc the new weights\n",
    "        w = (y - preds) + 2 * tau * h_diag * (0.5 - preds)\n",
    "        Ustar = X.T @ w\n",
    "        # print(f'{Ustar=}')\n",
    "        fisher_inv = -fisher_aug_inv.copy()\n",
    "        tmpKx1 = Ustar.T @ fisher_inv\n",
    "        tmp1x1 = tmpKx1.T @ Ustar\n",
    "        # print(f'{tmp1x1=}')\n",
    "        # print(f'fisher_augmented = {fisher_aug_inv[iSel, iSel]}')\n",
    "        under_root = -2 * ((LL0 - loglik) + 0.5 * tmp1x1) / fisher_aug_inv[iSel, iSel]\n",
    "        # print(f'{under_root=}')\n",
    "        lambda_ = 0 if under_root < 0 else which * np.sqrt(under_root)\n",
    "        # print(f'{lambda_=}')\n",
    "        Ustar[iSel] = Ustar[iSel] + lambda_\n",
    "        step_size = fisher_aug_inv.T @ Ustar\n",
    "        if max_halfstep >= 0:\n",
    "            mx = np.max(np.abs(step_size)) / max_halfstep\n",
    "            if mx > 1:\n",
    "                step_size = step_size / mx\n",
    "        # print(f'step_size={[x for x in step_size]}\\n')\n",
    "        coef = coef + step_size\n",
    "        # Iterate over halfsteps\n",
    "        loglik_old = loglik.copy()\n",
    "        for halfs in range(1, max_halfstep + 1):\n",
    "            preds = _get_preds(X, coef)\n",
    "            xw2 = _get_XW(X, preds).T\n",
    "            loglik = -_loglikelihood(X, y, preds)\n",
    "            fisher_info_matrix = xw2 @ xw2.T\n",
    "            fisher_det = np.linalg.det(fisher_info_matrix)\n",
    "            fisher_inv = np.linalg.inv(fisher_info_matrix)\n",
    "            # Calc hat diag and loglikelihood\n",
    "            tmpNxK = xw2.T @ fisher_inv\n",
    "            h_diag = np.diagonal(tmpNxK @ xw2)\n",
    "            loglik = -_loglikelihood(X, y, preds)\n",
    "            # Get augmented data\n",
    "            xw2_aug = _get_aug_XW(X, preds, tau, h_diag).T\n",
    "            fisher_aug = xw2_aug @ xw2_aug.T\n",
    "            fisher_aug_det = np.linalg.det(fisher_aug)\n",
    "            fisher_aug = np.linalg.inv(fisher_aug)\n",
    "            if (abs(loglik - LL0) < abs(loglik_old - LL0)) and (loglik > LL0):\n",
    "                break\n",
    "            step_size /= 2\n",
    "            coef -= step_size\n",
    "        if abs(loglik - LL0) <= tol:\n",
    "            lower_bds.append(coef[iSel])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "c56807e5-88ca-43cc-8395-df88aa3f69d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-6.923864735572734,\n",
       " 0.1845867771073193,\n",
       " 0.041972293104437036,\n",
       " -0.0029846187016573204,\n",
       " 0.014074318544182838,\n",
       " 0.0005828123655084136,\n",
       " 0.11804495417460169,\n",
       " 1.5181403571733085,\n",
       " 0.032864335783192394]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0f2205d7-e1ac-4451-a0e0-9af189ba5812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-9.706470179471,\n",
       " 0.05981888758405426,\n",
       " 0.027558848402368556,\n",
       " -0.023320855260184185,\n",
       " -0.012785547543677646,\n",
       " -0.0029204525872442745,\n",
       " 0.05937009703858033,\n",
       " 0.35283695211824373,\n",
       " -0.003424204408048102]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52791b-0237-428b-9ecb-660e70492a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSci",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
