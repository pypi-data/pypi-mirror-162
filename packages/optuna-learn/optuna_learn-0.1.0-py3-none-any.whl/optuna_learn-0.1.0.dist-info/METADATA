Metadata-Version: 2.1
Name: optuna-learn
Version: 0.1.0
Summary: A hyperparameter optimization framework via optuna.
Home-page: UNKNOWN
Author: zhangxjohn
Author-email: zhangxjohn@yeah.net
License: Apache License 2.0
Platform: UNKNOWN
Classifier: Operating System :: OS Independent
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: optuna

# optuna-learn

Tuning hyper-parameters based on Optuna is as easy as using scikit-learn.


## :hourglass_flowing_sand: Dependencies

optuna-learn requires:

- python >= 3.6
- scikit-learn 
- optuna 

## :zap: Quick Start

```python
from lightgbm import LGBMClassifier
from optlearn.opt import OptunaSearch
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

opt = OptunaSearch(
        model=LGBMClassifier,
        optimize_direction='minimize',
        params_dict={
            'n_estimators': ['categorical', 100, 200, 300, 500],
            'reg_alpha': ['float', 0.001, 10, False],
            'reg_lambda': ['float', 0.001, 100, False],
            'num_leaves': ['int', 2, 256],
        }
)

opt.fit(X_train, y_train)

y_pred = opt.predict(X_test)

accuracy_score(y_test, y_pred)
>>> 0.9967924528301886
```

